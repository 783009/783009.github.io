{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf38bde9-cf08-4570-b02a-442432712dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded\n",
      "Csv\n",
      "dupes\n",
      "Loading Train Data...\n",
      "Scanning 40 community models...\n",
      "Found 34 unique models out of 40.\n",
      "Building Community Stack...\n",
      "Community Ridge Score (CV): 8.585271\n",
      "\n",
      "Loading Elite Submissions...\n",
      "Loaded: 8.54853.csv\n",
      "Loaded: 8.54881.csv\n",
      "Loaded: 8.54905.csv\n",
      "\n",
      "SUCCESS! Created submission_titan_blend.csv\n",
      "This file blends your top scores with a deduplicated Ridge stack.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import hashlib\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print(\"Loaded\")\n",
    "\n",
    "# ==========================================\n",
    "# CONFIGURATION\n",
    "# ==========================================\n",
    "TARGET = 'exam_score'\n",
    "\n",
    "# Your \"Gold Standard\" files. \n",
    "# We trust the first one the most, but the others help smooth out noise.\n",
    "ELITE_SUBS = [\n",
    "    '8.54853.csv',  # The Anchor (Best)\n",
    "    '8.54881.csv',  # The Validator (2nd Best)\n",
    "    '8.54905.csv'   # The Validator (3rd Best)\n",
    "]\n",
    "print(\"Csv\")\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "def load_and_deduplicate():\n",
    "    \"\"\"Scans for OOF/SUB pairs and removes mathematical duplicates.\"\"\"\n",
    "    all_files = os.listdir('.')\n",
    "    oof_files = sorted([f for f in all_files if f.endswith('_oof.csv')])\n",
    "    \n",
    "    unique_prefixes = []\n",
    "    seen_hashes = set()\n",
    "    \n",
    "    print(f\"Scanning {len(oof_files)} community models...\")\n",
    "    \n",
    "    for f in oof_files:\n",
    "        prefix = f.replace('_oof.csv', '')\n",
    "        sub_file = f\"{prefix}_sub.csv\"\n",
    "        \n",
    "        if os.path.exists(sub_file):\n",
    "            # Load OOF to check fingerprint\n",
    "            try:\n",
    "                oof_data = pd.read_csv(f)[TARGET].values\n",
    "                file_hash = hashlib.md5(oof_data.tobytes()).hexdigest()\n",
    "                \n",
    "                if file_hash not in seen_hashes:\n",
    "                    seen_hashes.add(file_hash)\n",
    "                    unique_prefixes.append(prefix)\n",
    "                else:\n",
    "                    # Determine which file is being skipped for clarity\n",
    "                    pass \n",
    "            except Exception as e:\n",
    "                print(f\"Error reading {f}: {e}\")\n",
    "                \n",
    "    print(f\"Found {len(unique_prefixes)} unique models out of {len(oof_files)}.\")\n",
    "    return unique_prefixes\n",
    "\n",
    "print(\"dupes\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    # 1. Load Ground Truth\n",
    "    print(\"Loading Train Data...\")\n",
    "    train = pd.read_csv('train.csv')\n",
    "    y_true = train[TARGET].values\n",
    "    \n",
    "    # 2. Generate Community Stack (RidgeCV)\n",
    "    # This provides a 'consensus' baseline from the 40+ models\n",
    "    prefixes = load_and_deduplicate()\n",
    "    \n",
    "    print(\"Building Community Stack...\")\n",
    "    X_train = np.stack([pd.read_csv(f\"{p}_oof.csv\")[TARGET].values for p in prefixes], axis=1)\n",
    "    X_test = np.stack([pd.read_csv(f\"{p}_sub.csv\")[TARGET].values for p in prefixes], axis=1)\n",
    "    \n",
    "    # High-precision Ridge\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    # Finer alpha search for better regularization\n",
    "    alphas = np.logspace(-2, 5, 100) \n",
    "    \n",
    "    ridge = RidgeCV(alphas=alphas, scoring='neg_root_mean_squared_error', cv=kf)\n",
    "    ridge.fit(X_train, y_true)\n",
    "    \n",
    "    stack_preds = ridge.predict(X_test)\n",
    "    print(f\"Community Ridge Score (CV): {-ridge.best_score_:.6f}\")\n",
    "    \n",
    "    # 3. Load Elite Submissions\n",
    "    print(\"\\nLoading Elite Submissions...\")\n",
    "    elite_preds = []\n",
    "    valid_elites = []\n",
    "    \n",
    "    for f in ELITE_SUBS:\n",
    "        if os.path.exists(f):\n",
    "            print(f\"Loaded: {f}\")\n",
    "            elite_preds.append(pd.read_csv(f)[TARGET].values)\n",
    "            valid_elites.append(f)\n",
    "        else:\n",
    "            print(f\"Warning: {f} not found. Skipping.\")\n",
    "            \n",
    "    if not valid_elites:\n",
    "        print(\"CRITICAL ERROR: No Elite files found. Cannot perform blending.\")\n",
    "        return\n",
    "\n",
    "    # 4. The \"Titan\" Blend Logic\n",
    "    # We combine the \"Best File\", the \"Secondary Elites\", and the \"Stack\".\n",
    "    \n",
    "    # Part A: The Elite Average (Weighted towards the best)\n",
    "    # If we have all 3 files:\n",
    "    if len(elite_preds) >= 2:\n",
    "        # We give massive weight to the 8.54853 file\n",
    "        # But we mix in the others to reduce variance\n",
    "        p1 = elite_preds[0] # 8.54853\n",
    "        p2 = elite_preds[1] # 8.54881\n",
    "        \n",
    "        # This 80/20 split is a common heuristic to improve a top score\n",
    "        elite_ensemble = (p1 * 0.80) + (p2 * 0.20)\n",
    "        \n",
    "        if len(elite_preds) > 2:\n",
    "            p3 = elite_preds[2]\n",
    "            # Refined mix: 70% Best, 20% 2nd, 10% 3rd\n",
    "            elite_ensemble = (p1 * 0.70) + (p2 * 0.20) + (p3 * 0.10)\n",
    "    else:\n",
    "        elite_ensemble = elite_preds[0]\n",
    "\n",
    "    # Part B: Final Mix with Community Stack\n",
    "    # We trust the Elite Ensemble 95%, and the Community Stack 5%\n",
    "    # This 5% injection adds \"diversity\" without destroying the high accuracy.\n",
    "    final_preds = (elite_ensemble * 0.95) + (stack_preds * 0.05)\n",
    "\n",
    "    # 5. Post-Processing (Clipping)\n",
    "    # Synthetic data often stays within specific bounds\n",
    "    final_preds = np.clip(final_preds, 19.6, 100.0)\n",
    "    \n",
    "    # 6. Export\n",
    "    sub = pd.read_csv('sample_submission.csv')\n",
    "    sub[TARGET] = final_preds\n",
    "    output_filename = 'submission_titan_blend.csv'\n",
    "    sub.to_csv(output_filename, index=False)\n",
    "    \n",
    "    print(f\"\\nSUCCESS! Created {output_filename}\")\n",
    "    print(\"This file blends your top scores with a deduplicated Ridge stack.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141138f4-103d-443e-afe1-0e2e9cf48a0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
