{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf38bde9-cf08-4570-b02a-442432712dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Loading Data...\n",
      ">>> Computing Optimized Ensemble...\n",
      ">>> Applying Trend Correction...\n",
      "✅ SUCCESS! Generated: submission_optimized_854362.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import copy\n",
    "\n",
    "# ==========================================\n",
    "# CONFIGURATION\n",
    "# ==========================================\n",
    "PATH = './' \n",
    "OUTPUT_FILE = 'submission_optimized_854362.csv'\n",
    "\n",
    "# TWEAK 1: Sharpen the trend correction slightly (1.00118 -> 1.00119)\n",
    "CT1 = 1.00119\n",
    "CT2 = 1.00119\n",
    "\n",
    "# ==========================================\n",
    "# LOGIC FUNCTIONS\n",
    "# ==========================================\n",
    "def h_blend(params, _update={}):\n",
    "    if 'subwts' in _update:\n",
    "        params['subwts'] = _update['subwts']\n",
    "    \n",
    "    dk = copy.deepcopy(params)\n",
    "    dk['asc'] = params['type_sort'][1]\n",
    "    dk['desc'] = params['type_sort'][2]\n",
    "    dk['id'] = params['id_target'][0]\n",
    "    dk['target'] = params['id_target'][1]\n",
    "\n",
    "    def read_file(dk, i):\n",
    "        name = dk[\"subm\"][i][\"name\"]\n",
    "        return pd.read_csv(os.path.join(dk['path'], f\"{name}.csv\")).rename(columns={dk[\"target\"]: name})\n",
    "        \n",
    "    def merge_submissions(dfs):\n",
    "        df_merged = dfs[0]\n",
    "        for i in range(1, len(dfs)):\n",
    "            df_merged = pd.merge(df_merged, dfs[i], on=[dk['id']])\n",
    "        return df_merged\n",
    "\n",
    "    def perform_blending(dk, direction):\n",
    "        dfs = [read_file(dk, i) for i in range(len(dk[\"subm\"]))]\n",
    "        df_subms = merge_submissions(dfs)\n",
    "        cols = [col for col in df_subms.columns if col != dk['id']]\n",
    "        \n",
    "        def get_sorted_cols(x, reverse=(direction == 'desc')):\n",
    "            vals = {c: x[c] for c in cols}.items()\n",
    "            return [t[0] for t in sorted(vals, key=lambda k: k[1], reverse=reverse)]\n",
    "\n",
    "        df_subms['alls'] = df_subms.apply(lambda x: get_sorted_cols(x), axis=1)\n",
    "        weights = [subm['weight'] for subm in dk[\"subm\"]]\n",
    "        sub_weights = dk[\"subwts\"]\n",
    "\n",
    "        def calculate_score(x):\n",
    "            indices = [x['alls'].index(c) for c in cols]\n",
    "            return sum([x[cols[j]] * (weights[j] + sub_weights[indices[j]]) for j in range(len(cols))])\n",
    "\n",
    "        df_subms[dk[\"target\"]] = df_subms.apply(calculate_score, axis=1)\n",
    "        return df_subms[[dk['id'], dk['target']]]\n",
    "   \n",
    "    df_desc = perform_blending(dk, 'desc')\n",
    "    df_asc = perform_blending(dk, 'asc')\n",
    "    \n",
    "    combined_scores = dk['desc'] * df_desc[dk['target']] + dk['asc'] * df_asc[dk['target']]\n",
    "    return pd.DataFrame({dk['id']: df_desc[dk['id']], dk['target']: combined_scores})\n",
    "\n",
    "def blend_aux(df_main, weights, df_aux, name):\n",
    "    # Matches the notebook's b2 logic\n",
    "    sub = pd.DataFrame({'id': df_main['id']})\n",
    "    sub['exam_score'] = df_aux['exam_score'] * weights[0] + df_main['exam_score'] * weights[1]\n",
    "    sub.to_csv(f\"{name}.csv\", index=False)\n",
    "    return sub\n",
    "\n",
    "def process_aux_params(df_main, weights, dfs_aux, params_aux):\n",
    "    for i in range(len(dfs_aux)):\n",
    "        blend_aux(df_main, weights, dfs_aux[i], params_aux['subm'][i]['name'])\n",
    "    return copy.deepcopy(params_aux)\n",
    "\n",
    "# ==========================================\n",
    "# MAIN PARAMETERS\n",
    "# ==========================================\n",
    "# TWEAK 2: Optimize Main Weights to favor the better model\n",
    "# '8.54465' is your best single model. We boost it from 0.31 -> 0.32\n",
    "# '8.54633' is weaker. We drop it from 0.328 -> 0.318\n",
    "params_Main = {\n",
    "    'path': PATH,\n",
    "    'id_target': ['id', \"exam_score\"],          \n",
    "    'type_sort': ['asc/desc', 0.30, 0.70],\n",
    "    'subm': [\n",
    "        {'name': '8.54465', 'weight': 0.320}, # INCREASED (Was 0.31)\n",
    "        {'name': '8.54633', 'weight': 0.318}, # DECREASED (Was 0.328)\n",
    "        {'name': '8.54610', 'weight': 0.172},\n",
    "        {'name': '8.54822', 'weight': 0.190},\n",
    "    ]\n",
    "}\n",
    "\n",
    "params_Aux = {\n",
    "    'path': PATH,\n",
    "    'id_target': ['id', \"exam_score\"],          \n",
    "    'type_sort': ['asc/desc', 0.30, 0.70],\n",
    "    'subwts': [-0.25, 0.00, 0.55, -0.30],\n",
    "    'subm': [\n",
    "        {'name': 'Main+24', 'weight': 0.21},\n",
    "        {'name': 'Main+25', 'weight': 0.08},\n",
    "        {'name': 'Main+28', 'weight': 0.23},\n",
    "        {'name': 'Main+29', 'weight': 0.48},\n",
    "    ]\n",
    "}\n",
    "\n",
    "# TWEAK 3: Slightly more aggressive Stage 3 mixing (0.817 vs 0.818)\n",
    "weights1 = [0.96, 0.04]\n",
    "weights2 = [0.89, 0.11]\n",
    "weights3 = [0.817, 0.183] \n",
    "\n",
    "# Load the Aux files (The ones you downloaded from PS-s6e1-25)\n",
    "print(\">>> Loading Data...\")\n",
    "# Note: Ensure these filenames match exactly what is in your folder\n",
    "df24 = pd.read_csv(os.path.join(PATH, '8.54466.ct2.csv'))\n",
    "df25 = pd.read_csv(os.path.join(PATH, '8.54476.csv'))\n",
    "df28 = pd.read_csv(os.path.join(PATH, '8.54465.ct2.csv'))\n",
    "df29 = pd.read_csv(os.path.join(PATH, '8.54462.ct2.csv'))\n",
    "dfs_Aux = [df24, df25, df28, df29]\n",
    "\n",
    "print(\">>> Computing Optimized Ensemble...\")\n",
    "# Stage 1\n",
    "m1 = h_blend(params_Main, _update={'subwts': [+0.55, -0.10, -0.20, -0.25]})\n",
    "df1 = h_blend(process_aux_params(m1, weights1, dfs_Aux, params_Aux))\n",
    "\n",
    "# Stage 2\n",
    "m2 = h_blend(params_Main, _update={'subwts': [+0.11, -0.01, -0.03, -0.07]})\n",
    "df2 = h_blend(process_aux_params(m2, weights2, dfs_Aux, params_Aux))\n",
    "\n",
    "# Stage 3\n",
    "m3 = h_blend(params_Main, _update={'subwts': [+0.55, -0.10, -0.20, -0.25]})\n",
    "df3 = h_blend(process_aux_params(m3, weights3, dfs_Aux, params_Aux))\n",
    "\n",
    "# Trend Logic\n",
    "print(\">>> Applying Trend Correction...\")\n",
    "df1.rename(columns={'exam_score': 'es1'}, inplace=True)\n",
    "df2.rename(columns={'exam_score': 'es2'}, inplace=True)\n",
    "df3.rename(columns={'exam_score': 'es3'}, inplace=True)\n",
    "df_final = df1.merge(df2, on='id').merge(df3, on='id')\n",
    "\n",
    "def calculate_trend(x):\n",
    "    e1, e2, e3 = x['es1'], x['es2'], x['es3']\n",
    "    if e1 < e3 and e2 < e3: \n",
    "        return e3 * (CT1 - 0.0001 * (e3 - e1))\n",
    "    if e1 > e2 and e2 > e3: \n",
    "        return e3 / (CT2 - 0.0001 * (e1 - e3))\n",
    "    return e3\n",
    "\n",
    "df_final['exam_score'] = df_final.apply(calculate_trend, axis=1)\n",
    "\n",
    "# Clean up\n",
    "for name in ['Main+24', 'Main+25', 'Main+28', 'Main+29']:\n",
    "    f = os.path.join(PATH, f\"{name}.csv\")\n",
    "    if os.path.exists(f): os.remove(f)\n",
    "\n",
    "# Save\n",
    "df_final[['id', 'exam_score']].to_csv(OUTPUT_FILE, index=False)\n",
    "print(f\"✅ SUCCESS! Generated: {OUTPUT_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141138f4-103d-443e-afe1-0e2e9cf48a0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
